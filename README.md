# Milo AI - Guide d'installation

Ce guide vous explique comment installer et d√©marrer le projet Milo AI sur un nouveau PC, que ce soit sous Windows ou macOS.

## üìã Pr√©requis

Avant de commencer, vous devez installer les logiciels suivants :

### Logiciels n√©cessaires

1. **Python 3.13** (ou Python 3.12 compatible)
2. **Redis** (pour la messagerie)
3. **Ollama** (pour les mod√®les LLM)
4. **FFmpeg** (pour le traitement audio)

---

## ü™ü Installation sur Windows

### √âtape 1 : Installer Python

1. T√©l√©chargez Python 3.13 depuis [python.org](https://www.python.org/downloads/)
2. **Important** : Cochez "Add Python to PATH" lors de l'installation
3. V√©rifiez l'installation :
   ```cmd
   python --version
   ```

### √âtape 2 : Installer Redis

**Option A - Via WSL (recommand√©) :**
1. Installez WSL2 si ce n'est pas d√©j√† fait :
   ```cmd
   wsl --install
   ```
2. Dans WSL, installez Redis :
   ```bash
   sudo apt update
   sudo apt install redis-server
   redis-server --daemonize yes
   ```

**Option B - Via Chocolatey :**
```cmd
choco install redis-64
```

**Option C - T√©l√©chargement manuel :**
T√©l√©chargez Redis depuis [github.com/microsoftarchive/redis](https://github.com/microsoftarchive/redis/releases)

### √âtape 3 : Installer Ollama

1. T√©l√©chargez Ollama depuis [ollama.ai](https://ollama.ai/download)
2. Installez l'application
3. T√©l√©chargez les mod√®les n√©cessaires :
   ```cmd
   ollama pull nchapman/ministral-8b-instruct-2410:8b
   ollama pull granite3.1-dense:2b
   ```

### √âtape 4 : Installer FFmpeg

**Option A - Via Chocolatey :**
```cmd
choco install ffmpeg
```

**Option B - T√©l√©chargement manuel :**
1. T√©l√©chargez depuis [ffmpeg.org](https://ffmpeg.org/download.html)
2. Ajoutez FFmpeg au PATH de Windows

### √âtape 5 : Cloner/Pr√©parer le projet

1. Ouvrez PowerShell ou CMD dans le dossier du projet
2. Cr√©ez un environnement virtuel :
   ```cmd
   python -m venv venv
   ```
3. Activez l'environnement virtuel :
   ```cmd
   venv\Scripts\activate
   ```
4. Installez les d√©pendances :
   ```cmd
   pip install --upgrade pip
   pip install -r requirements.txt
   ```

### √âtape 6 : V√©rifier le mod√®le TTS

Assurez-vous que le fichier suivant existe :
```
audio/tts_models/fr_FR-upmc-medium.onnx
```

Si le fichier s'appelle `fr_FR-upmc-medium.onnx.1`, copiez-le :
```cmd
copy audio\tts_models\fr_FR-upmc-medium.onnx.1 audio\tts_models\fr_FR-upmc-medium.onnx
```

### √âtape 7 : D√©marrer les services

**Terminal 1 - Redis :**
```cmd
redis-server
```

**Terminal 2 - Application :**
```cmd
venv\Scripts\activate
python src\back_launcher.py
```

L'application sera accessible sur : **http://localhost:5001**

---

## üçé Installation sur macOS

### √âtape 1 : Installer Homebrew (si pas d√©j√† install√©)

```bash
/bin/bash -c "$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)"
```

### √âtape 2 : Installer Python

```bash
brew install python@3.13
```

V√©rifiez l'installation :
```bash
python3.13 --version
```

### √âtape 3 : Installer Redis

```bash
brew install redis
brew services start redis
```

V√©rifiez que Redis fonctionne :
```bash
redis-cli ping
# Devrait r√©pondre : PONG
```

### √âtape 4 : Installer Ollama

```bash
brew install ollama
```

Ou t√©l√©chargez depuis [ollama.ai](https://ollama.ai/download)

T√©l√©chargez les mod√®les n√©cessaires :
```bash
ollama pull nchapman/ministral-8b-instruct-2410:8b
ollama pull granite3.1-dense:2b
```

### √âtape 5 : Installer FFmpeg

```bash
brew install ffmpeg
```

### √âtape 6 : Pr√©parer le projet

1. Ouvrez un terminal dans le dossier du projet
2. Cr√©ez un environnement virtuel :
   ```bash
   python3.13 -m venv venv
   ```
3. Activez l'environnement virtuel :
   ```bash
   source venv/bin/activate
   ```
4. Installez les d√©pendances :
   ```bash
   pip install --upgrade pip
   pip install -r requirements.txt
   ```

### √âtape 7 : V√©rifier le mod√®le TTS

Assurez-vous que le fichier suivant existe :
```
audio/tts_models/fr_FR-upmc-medium.onnx
```

Si le fichier s'appelle `fr_FR-upmc-medium.onnx.1`, copiez-le :
```bash
cp audio/tts_models/fr_FR-upmc-medium.onnx.1 audio/tts_models/fr_FR-upmc-medium.onnx
```

### √âtape 8 : D√©marrer l'application

```bash
source venv/bin/activate
python src/back_launcher.py
```

L'application sera accessible sur : **http://localhost:5001**

---

## üîß D√©pannage

### Probl√®me : "ModuleNotFoundError: No module named 'flask'"

**Solution :**
- Assurez-vous que l'environnement virtuel est activ√©
- R√©installez les d√©pendances : `pip install -r requirements.txt`

### Probl√®me : "No module named 'flask'" m√™me apr√®s installation

**Solution :**
- V√©rifiez que vous utilisez le bon Python : `which python` (macOS) ou `where python` (Windows)
- Utilisez directement le Python du venv : `./venv/bin/python src/back_launcher.py` (macOS) ou `venv\Scripts\python src\back_launcher.py` (Windows)

### Probl√®me : "ONNXRuntimeError: Load model failed. File doesn't exist"

**Solution :**
- V√©rifiez que `audio/tts_models/fr_FR-upmc-medium.onnx` existe
- Si vous avez `fr_FR-upmc-medium.onnx.1`, copiez-le vers `fr_FR-upmc-medium.onnx`

### Probl√®me : "Connection refused" ou erreur Redis

**Solution :**
- V√©rifiez que Redis est en cours d'ex√©cution :
  - Windows (WSL) : `redis-cli ping`
  - macOS : `redis-cli ping` ou `brew services list` pour v√©rifier
- D√©marrez Redis si n√©cessaire :
  - Windows (WSL) : `redis-server`
  - macOS : `brew services start redis`

### Probl√®me : "ctranslate2" n'est pas disponible pour votre version de Python

**Solution :**
- Utilisez Python 3.13 ou 3.12 (pas Python 3.14+)
- Recr√©ez l'environnement virtuel avec la bonne version :
  ```bash
  rm -rf venv
  python3.13 -m venv venv
  source venv/bin/activate
  pip install -r requirements.txt
  ```

### Probl√®me : Ollama ne trouve pas les mod√®les

**Solution :**
- V√©rifiez que Ollama est install√© : `ollama --version`
- T√©l√©chargez les mod√®les manuellement :
  ```bash
  ollama pull nchapman/ministral-8b-instruct-2410:8b
  ollama pull granite3.1-dense:2b
  ```

---

## üìÅ Structure du projet

```
milo_ai-main/
‚îú‚îÄ‚îÄ audio/                    # Dossiers audio
‚îÇ   ‚îú‚îÄ‚îÄ tts_models/          # Mod√®les TTS (fr_FR-upmc-medium.onnx)
‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îú‚îÄ‚îÄ front/                    # Interface frontend
‚îú‚îÄ‚îÄ src/                      # Code source backend
‚îÇ   ‚îú‚îÄ‚îÄ back_launcher.py     # Point d'entr√©e principal
‚îÇ   ‚îî‚îÄ‚îÄ lib/                 # Modules Python
‚îú‚îÄ‚îÄ requirements.txt          # D√©pendances Python
‚îî‚îÄ‚îÄ README.md                # Ce fichier
```

---

## üöÄ Commandes rapides

### macOS / Linux

```bash
# Activer l'environnement virtuel
source venv/bin/activate

# Lancer le serveur
python src/back_launcher.py

# V√©rifier Redis
redis-cli ping

# V√©rifier Ollama
ollama list
```

### Windows

```cmd
REM Activer l'environnement virtuel
venv\Scripts\activate

REM Lancer le serveur
python src\back_launcher.py

REM V√©rifier Redis (dans WSL)
wsl redis-cli ping

REM V√©rifier Ollama
ollama list
```

---

## üìû Support

En cas de probl√®me, v√©rifiez :
1. ‚úÖ Python 3.13 install√© et dans le PATH
2. ‚úÖ Redis en cours d'ex√©cution
3. ‚úÖ Ollama install√© avec les mod√®les t√©l√©charg√©s
4. ‚úÖ FFmpeg install√©
5. ‚úÖ Tous les packages Python install√©s dans le venv
6. ‚úÖ Le mod√®le TTS pr√©sent dans `audio/tts_models/`

---

## üìù Notes importantes

- Le projet utilise le port **5001** pour le serveur Flask
- Redis doit tourner sur le port **6379** (par d√©faut)
- Les mod√®les Ollama sont t√©l√©charg√©s automatiquement au premier lancement si Ollama est install√©
- Le mod√®le Whisper (transcription) est t√©l√©charg√© automatiquement au premier lancement

---

**Bon d√©veloppement ! üöÄ**

